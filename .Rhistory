mod <- lm(im ~ pcs10 + 0)
rsq = summary(mod)$adj.r.squared
if (rsq > max.r) {
max.r = rsq
max.level = levs[[i]]
}
}
if (max.level == levs[[level]]) {
numcorrect = numcorrect + 1
}
}
print(levs[[level]])
print(numcorrect/200.0)
}
for (level in 1:10) {
dat <- trainLabels$V1 == levs[[level]]
dat.cat <- training_X_gray[dat,]
dat.val <- dat.cat[-t,]
numcorrect = 0
for (index in 1:2000) {
im <- t(as.data.frame(dat.val[index,]))
max.r = 0
max.level = ""
for (i in 1:10){
pcs10 = pcs_list[[i]]
mod <- lm(im ~ pcs10)
rsq = summary(mod)$adj.r.squared
if (rsq > max.r) {
max.r = rsq
max.level = levs[[i]]
}
}
if (max.level == levs[[level]]) {
numcorrect = numcorrect + 1
}
}
print(levs[[level]])
print(numcorrect/2000.0)
}
0.2585 + 0.336 + 0.379 + .195 + .2315 + .1485 + .169 + .2685 + .289+ .347
t <- sample(1:5000,3000)
levs <- levels(trainLabels$V1)
pcs_list  <- list()
i = 1
for (cat in levs){
dat <- trainLabels$V1 == cat
dat.cat <- training_X_gray[dat,]
dat.train <- dat.cat[t,]
train.pc <- prcomp(dat.train)
pcs10 <- train.pc$rotation[,1:3]
pcs_list[[i]] <- pcs10
i = i + 1
}
for (level in 1:10) {
dat <- trainLabels$V1 == levs[[level]]
dat.cat <- training_X_gray[dat,]
dat.val <- dat.cat[-t,]
numcorrect = 0
for (index in 1:2000) {
im <- t(as.data.frame(dat.val[index,]))
max.r = 0
max.level = ""
for (i in 1:10){
pcs10 = pcs_list[[i]]
mod <- lm(im ~ pcs10)
rsq = summary(mod)$adj.r.squared
if (rsq > max.r) {
max.r = rsq
max.level = levs[[i]]
}
}
if (max.level == levs[[level]]) {
numcorrect = numcorrect + 1
}
}
print(levs[[level]])
print(numcorrect/2000.0)
}
inds = list()
for(i=1:100){
low = ((i-1)*3000 + 1)
high = low + 3000
new_inds = low:high
inds = c(inds,new_inds)
}
inds = list()
for(i in 1:100){
low = ((i-1)*3000 + 1)
high = low + 3000
new_inds = low:high
inds = c(inds,new_inds)
}
inds
inds = list()
for(i in 1:100){
low = ((i-1)*3000 + 1)
high = low + 299
new_inds = low:high
inds = c(inds,new_inds)
}
inds = list()
for(i in 1:100){
low = ((i-1)*3000 + 1)
high = low + 2999
new_inds = low:high
inds = c(inds,new_inds)
}
aug_neural_net_chan80_kern77 <- read.csv("~/Desktop/COMP_540/Competition/Submissions/aug_neural_net_chan80_kern77.csv")
View(aug_neural_net_chan80_kern77)
nd <- aug_neural_net_chan80_kern77[inds,]
inds = as.data.frame(inds)
nd <- aug_neural_net_chan80_kern77[inds,]
inds = list()
for(i in 1:100){
low = ((i-1)*3000 + 1)
high = low + 2999
new_inds = low:high
inds = c(inds,new_inds)
}
nd <- aug_neural_net_chan80_kern77[label][[inds]]
nd <- aug_neural_net_chan80_kern77$label[[inds]]
nd <- aug_neural_net_chan80_kern77$label[inds]
nd <- aug_neural_net_chan80_kern77$label[as.matrix(inds)]
inds2 = as.vector(inds)
nd <- aug_neural_net_chan80_kern77$label[inds2]
nd <- aug_neural_net_chan80_kern77[1:3000,]
View(nd)
nd <- aug_neural_net_chan80_kern77[1:3000,]
for(i in 1:100){
low = ((i-1)*3000 + 1)
high = low + 2999
n <- aug_neural_net_chan80_kern77[low:high,]
nd <- rbind(nd,n)
}
nd <- aug_neural_net_chan80_kern77[1:3000,]
for(i in 2:100){
low = ((i-1)*3000 + 1)
high = low + 2999
n <- aug_neural_net_chan80_kern77[low:high,]
nd <- rbind(nd,n)
}
View(nd)
inds = list()
nd <- aug_neural_net_chan80_kern77[1:3000,]
for(i in 2:100){
low = ((i-1)*6000 + 1)
high = low + 2999
n <- aug_neural_net_chan80_kern77[low:high,]
nd <- rbind(nd,n)
}
View(nd)
View(n)
write.csv(nd,'aug_nerual_net_chan80_kern77_3.csv')
nd$id = 1:300000
write.csv(nd,'aug_nerual_net_chan80_kern77_3.csv',index=FALSE)
write.csv(nd,'aug_nerual_net_chan80_kern77_3.csv',index=None)
write.csv(nd,'aug_nerual_net_chan80_kern77_3.csv',labels=FALSE)
write.csv(nd,'aug_nerual_net_chan80_kern77_3.csv', col.names = FALSE)
write.csv(nd,'aug_nerual_net_chan80_kern77_3.csv', row.names = FALSE)
primary_results <- read.csv("~/Desktop/COMP_502/2016_presidential_election/primary_results.csv")
View(primary_results)
len(unique(primary_results$fips))
length(unique(primary_results$fips))
length(primary_results$candidate == 'Donald Trump')
sum(primary_results$candidate == 'Donald Trump')
county_facts <- read.csv("~/Desktop/COMP_502/2016_presidential_election/county_facts.csv", header=FALSE)
View(county_facts)
###############################
# Load required package(s)
################################
require(neuralnet)
################################
# Read In Data
################################
county_facts <- read.csv("2016_presidential_election/county_facts.csv")
primary_results <- read.csv("2016_presidential_election/primary_results.csv")
trump <- primary_results[primary_results$candidate == 'Donald Trump',]
trump2 <- as.data.frame(cbind(trump$fips,trump$fraction_votes))
names(trump2) <- c('fips','fraction_votes')
trump_county_facts <- merge(trump2, county_facts, by = 'fips', all.x = TRUE, all.y = FALSE)
trump_county_facts <- subset(trump_county_facts, select = -c(area_name,state_abbreviation))
setwd('/Users/scottmorgan/Desktop/COMP_502/Final Project/TrumpNN')
###############################################################################
##
##  trumpNN.R: fits a neural network with one hidden layer to predict
##             the fraction of the votes in each county in NH, IA, SC, NV
##             that Donald Trump recieved based on demographics
##
###############################################################################
################################
# Load required package(s)
################################
require(neuralnet)
################################
# Read In Data
################################
county_facts <- read.csv("2016_presidential_election/county_facts.csv")
primary_results <- read.csv("2016_presidential_election/primary_results.csv")
trump <- primary_results[primary_results$candidate == 'Donald Trump',]
trump2 <- as.data.frame(cbind(trump$fips,trump$fraction_votes))
names(trump2) <- c('fips','fraction_votes')
trump_county_facts <- merge(trump2, county_facts, by = 'fips', all.x = TRUE, all.y = FALSE)
trump_county_facts <- subset(trump_county_facts, select = -c(area_name,state_abbreviation))
columns_of_interest <- c("EDU685213", "INC110213", "RHI225214", "POP060210")
X <- trump_county_facts[,columns_of_interest]
Y <- as.data.frame(trump_county_facts[,2])
names(Y) <- c("fraction_votes")
################################
#  Fit Neural Net
################################
# Get indices for test set and split data
test_inds <- sample(1:1881,30)
Xtrain <- X[-test_inds,]
Xtest <- X[test_inds,]
Ytrain <- Y[-test_inds,]
Ytest <- Y[test_inds,]
# Scale Xtrain, Xtest and Ytrain, Ytest by Xtrain and Ytrain ([0,1] scaling)
maxs <- apply(Xtrain, 2, function(x) max(x, na.rm = TRUE))
mins <- apply(Xtrain, 2, function(x) min(x, na.rm = TRUE))
Xtrain <- apply(Xtrain,2,function(x){(x-min(x))/(max(x)-min(x))})
Xtest <- apply(Xtest,2,function(x){(x-min(x))/(max(x)-min(x))})
maxy <- max(Ytrain)
miny <- min(Ytrain)
Ytrain <- ((Ytrain - miny)/(maxy-miny))
Ytest <- ((Ytest - miny)/(maxy-miny))
# Actually fit the neural net. Have to do weird thing with formula because it doesn accept "~."
dat <- as.data.frame(cbind(Ytrain,Xtrain))
names(dat)[1] <- c('D')
n <- names(dat)
f <- as.formula(paste("D ~", paste(n[!n %in% "D"], collapse = " + ")))
mod <- neuralnet(f, data = dat, hidden = 4, act.fct = "tanh", stepmax = 1e+07, linear.output = FALSE)
################################
#  Evaluate Results
################################
# predict the values using training and test set
Y_fit_train <- compute(mod, Xtrain)$net.result
Y_fit_test <- compute(mod, Xtest)$net.result
# MSE in scaled space
mse_train <- sqrt(mean((Y_fit_train - Ytrain)^2))
mse_test <- sqrt(mean((Y_fit_test - Ytest)^2))
# MSE of just choosing the mean (benchmark to beat)
benchmark_train <- sqrt(mean((Ytrain - mean(Ytrain))^2))
benchmark_test <- sqrt(mean((Ytest - mean(Ytest))^2))
sprintf("Training MSE: %.4f", mse_train)
sprintf('... Training Benchmark: %.4f', benchmark_train)
sprintf("Testing MSE: %.4f", mse_test)
sprintf('... Testing Benchmark: %.4f', benchmark_test)
mod <- neuralnet(f, data = dat, hidden = 7, act.fct = "tanh", stepmax = 1e+07, linear.output = FALSE)
################################
#  Evaluate Results
################################
# predict the values using training and test set
Y_fit_train <- compute(mod, Xtrain)$net.result
Y_fit_test <- compute(mod, Xtest)$net.result
# MSE in scaled space
mse_train <- sqrt(mean((Y_fit_train - Ytrain)^2))
mse_test <- sqrt(mean((Y_fit_test - Ytest)^2))
# MSE of just choosing the mean (benchmark to beat)
benchmark_train <- sqrt(mean((Ytrain - mean(Ytrain))^2))
benchmark_test <- sqrt(mean((Ytest - mean(Ytest))^2))
sprintf("Training MSE: %.4f", mse_train)
sprintf('... Training Benchmark: %.4f', benchmark_train)
sprintf("Testing MSE: %.4f", mse_test)
sprintf('... Testing Benchmark: %.4f', benchmark_test)
columns_of_interest <- c("EDU685213", "INC110213", "RHI225214", "POP060210", "AGE775214")
X <- trump_county_facts[,columns_of_interest]
Y <- as.data.frame(trump_county_facts[,2])
names(Y) <- c("fraction_votes")
################################
#  Fit Neural Net
################################
# Get indices for test set and split data
test_inds <- sample(1:1881,30)
Xtrain <- X[-test_inds,]
Xtest <- X[test_inds,]
Ytrain <- Y[-test_inds,]
Ytest <- Y[test_inds,]
# Scale Xtrain, Xtest and Ytrain, Ytest by Xtrain and Ytrain ([0,1] scaling)
maxs <- apply(Xtrain, 2, function(x) max(x, na.rm = TRUE))
mins <- apply(Xtrain, 2, function(x) min(x, na.rm = TRUE))
Xtrain <- apply(Xtrain,2,function(x){(x-min(x))/(max(x)-min(x))})
Xtest <- apply(Xtest,2,function(x){(x-min(x))/(max(x)-min(x))})
maxy <- max(Ytrain)
miny <- min(Ytrain)
Ytrain <- ((Ytrain - miny)/(maxy-miny))
Ytest <- ((Ytest - miny)/(maxy-miny))
# Actually fit the neural net. Have to do weird thing with formula because it doesn accept "~."
dat <- as.data.frame(cbind(Ytrain,Xtrain))
names(dat)[1] <- c('D')
n <- names(dat)
f <- as.formula(paste("D ~", paste(n[!n %in% "D"], collapse = " + ")))
mod <- neuralnet(f, data = dat, hidden = 7, act.fct = "tanh", stepmax = 1e+07, linear.output = FALSE)
################################
#  Evaluate Results
################################
# predict the values using training and test set
Y_fit_train <- compute(mod, Xtrain)$net.result
Y_fit_test <- compute(mod, Xtest)$net.result
# MSE in scaled space
mse_train <- sqrt(mean((Y_fit_train - Ytrain)^2))
mse_test <- sqrt(mean((Y_fit_test - Ytest)^2))
# MSE of just choosing the mean (benchmark to beat)
benchmark_train <- sqrt(mean((Ytrain - mean(Ytrain))^2))
benchmark_test <- sqrt(mean((Ytest - mean(Ytest))^2))
sprintf("Training MSE: %.4f", mse_train)
sprintf('... Training Benchmark: %.4f', benchmark_train)
sprintf("Testing MSE: %.4f", mse_test)
sprintf('... Testing Benchmark: %.4f', benchmark_test)
################################
# Pull out columns of interest
################################
# % over 65:"AGE775214", % black: "RHI225214",
# % hispanic: "RHI725214", % white: "RHI825214", % foreign born: "POP645213"
# % bachelors: "EDU685213", % veteran: "VET605213", median hh income: "INC110213",
# pop per sqm: "POP060210",
columns_of_interest <- c("EDU685213", "INC110213", "RHI225214", "POP060210", "AGE775214")
X <- trump_county_facts[,columns_of_interest]
Y <- as.data.frame(trump_county_facts[,2])
names(Y) <- c("fraction_votes")
################################
#  Fit Neural Net
################################
# Get indices for test set and split data
test_inds <- sample(1:1881,30)
Xtrain <- X[-test_inds,]
Xtest <- X[test_inds,]
Ytrain <- Y[-test_inds,]
Ytest <- Y[test_inds,]
# Scale Xtrain, Xtest and Ytrain, Ytest by Xtrain and Ytrain ([0,1] scaling)
maxs <- apply(Xtrain, 2, function(x) max(x, na.rm = TRUE))
mins <- apply(Xtrain, 2, function(x) min(x, na.rm = TRUE))
Xtrain <- apply(Xtrain,2,function(x){(x-min(x))/(max(x)-min(x))})
Xtest <- apply(Xtest,2,function(x){(x-min(x))/(max(x)-min(x))})
maxy <- max(Ytrain)
miny <- min(Ytrain)
Ytrain <- ((Ytrain - miny)/(maxy-miny))
Ytest <- ((Ytest - miny)/(maxy-miny))
# Actually fit the neural net. Have to do weird thing with formula because it doesn accept "~."
dat <- as.data.frame(cbind(Ytrain,Xtrain))
names(dat)[1] <- c('D')
n <- names(dat)
f <- as.formula(paste("D ~", paste(n[!n %in% "D"], collapse = " + ")))
mod <- neuralnet(f, data = dat, hidden = 4, act.fct = "tanh", stepmax = 1e+07)
################################
#  Evaluate Results
################################
# predict the values using training and test set
Y_fit_train <- compute(mod, Xtrain)$net.result
Y_fit_test <- compute(mod, Xtest)$net.result
# MSE in scaled space
mse_train <- sqrt(mean((Y_fit_train - Ytrain)^2))
mse_test <- sqrt(mean((Y_fit_test - Ytest)^2))
# MSE of just choosing the mean (benchmark to beat)
benchmark_train <- sqrt(mean((Ytrain - mean(Ytrain))^2))
benchmark_test <- sqrt(mean((Ytest - mean(Ytest))^2))
sprintf("Training MSE: %.4f", mse_train)
sprintf('... Training Benchmark: %.4f', benchmark_train)
sprintf("Testing MSE: %.4f", mse_test)
sprintf('... Testing Benchmark: %.4f', benchmark_test)
################################
# Pull out columns of interest
################################
# % over 65:"AGE775214", % black: "RHI225214",
# % hispanic: "RHI725214", % white: "RHI825214", % foreign born: "POP645213"
# % bachelors: "EDU685213", % veteran: "VET605213", median hh income: "INC110213",
# pop per sqm: "POP060210",
columns_of_interest <- c("EDU685213", "RHI225214", "RHI725214")
X <- trump_county_facts[,columns_of_interest]
Y <- as.data.frame(trump_county_facts[,2])
names(Y) <- c("fraction_votes")
################################
#  Fit Neural Net
################################
# Get indices for test set and split data
test_inds <- sample(1:1881,30)
Xtrain <- X[-test_inds,]
Xtest <- X[test_inds,]
Ytrain <- Y[-test_inds,]
Ytest <- Y[test_inds,]
# Scale Xtrain, Xtest and Ytrain, Ytest by Xtrain and Ytrain ([0,1] scaling)
maxs <- apply(Xtrain, 2, function(x) max(x, na.rm = TRUE))
mins <- apply(Xtrain, 2, function(x) min(x, na.rm = TRUE))
Xtrain <- apply(Xtrain,2,function(x){(x-min(x))/(max(x)-min(x))})
Xtest <- apply(Xtest,2,function(x){(x-min(x))/(max(x)-min(x))})
maxy <- max(Ytrain)
miny <- min(Ytrain)
Ytrain <- ((Ytrain - miny)/(maxy-miny))
Ytest <- ((Ytest - miny)/(maxy-miny))
# Actually fit the neural net. Have to do weird thing with formula because it doesn accept "~."
dat <- as.data.frame(cbind(Ytrain,Xtrain))
names(dat)[1] <- c('D')
n <- names(dat)
f <- as.formula(paste("D ~", paste(n[!n %in% "D"], collapse = " + ")))
mod <- neuralnet(f, data = dat, hidden = 4, act.fct = "tanh", stepmax = 1e+07)
################################
#  Evaluate Results
################################
# predict the values using training and test set
Y_fit_train <- compute(mod, Xtrain)$net.result
Y_fit_test <- compute(mod, Xtest)$net.result
# MSE in scaled space
mse_train <- sqrt(mean((Y_fit_train - Ytrain)^2))
mse_test <- sqrt(mean((Y_fit_test - Ytest)^2))
# MSE of just choosing the mean (benchmark to beat)
benchmark_train <- sqrt(mean((Ytrain - mean(Ytrain))^2))
benchmark_test <- sqrt(mean((Ytest - mean(Ytest))^2))
sprintf("Training MSE: %.4f", mse_train)
sprintf('... Training Benchmark: %.4f', benchmark_train)
sprintf("Testing MSE: %.4f", mse_test)
sprintf('... Testing Benchmark: %.4f', benchmark_test)
################################
# Pull out columns of interest
################################
# % over 65:"AGE775214", % black: "RHI225214",
# % hispanic: "RHI725214", % white: "RHI825214", % foreign born: "POP645213"
# % bachelors: "EDU685213", % veteran: "VET605213", median hh income: "INC110213",
# pop per sqm: "POP060210",
columns_of_interest <- c("EDU685213", "RHI225214", "RHI725214")
X <- trump_county_facts[,columns_of_interest]
Y <- as.data.frame(trump_county_facts[,2])
names(Y) <- c("fraction_votes")
################################
#  Fit Neural Net
################################
# Get indices for test set and split data
test_inds <- sample(1:1881,30)
Xtrain <- X[-test_inds,]
Xtest <- X[test_inds,]
Ytrain <- Y[-test_inds,]
Ytest <- Y[test_inds,]
# Scale Xtrain, Xtest and Ytrain, Ytest by Xtrain and Ytrain ([0,1] scaling)
maxs <- apply(Xtrain, 2, function(x) max(x, na.rm = TRUE))
mins <- apply(Xtrain, 2, function(x) min(x, na.rm = TRUE))
Xtrain <- apply(Xtrain,2,function(x){(x-min(x))/(max(x)-min(x))})
Xtest <- apply(Xtest,2,function(x){(x-min(x))/(max(x)-min(x))})
maxy <- max(Ytrain)
miny <- min(Ytrain)
Ytrain <- ((Ytrain - miny)/(maxy-miny))
Ytest <- ((Ytest - miny)/(maxy-miny))
# Actually fit the neural net. Have to do weird thing with formula because it doesn accept "~."
dat <- as.data.frame(cbind(Ytrain,Xtrain))
names(dat)[1] <- c('D')
n <- names(dat)
f <- as.formula(paste("D ~", paste(n[!n %in% "D"], collapse = " + ")))
mod <- neuralnet(f, data = dat, hidden = 4, act.fct = "tanh", stepmax = 1e+07)
################################
#  Evaluate Results
################################
# predict the values using training and test set
Y_fit_train <- compute(mod, Xtrain)$net.result
Y_fit_test <- compute(mod, Xtest)$net.result
# MSE in scaled space
mse_train <- sqrt(mean((Y_fit_train - Ytrain)^2))
mse_test <- sqrt(mean((Y_fit_test - Ytest)^2))
# MSE of just choosing the mean (benchmark to beat)
benchmark_train <- sqrt(mean((Ytrain - mean(Ytrain))^2))
benchmark_test <- sqrt(mean((Ytest - mean(Ytest))^2))
sprintf("Training RMSE: %.4f", mse_train)
sprintf('... Training Benchmark: %.4f', benchmark_train)
sprintf("Testing RMSE: %.4f", mse_test)
sprintf('... Testing Benchmark: %.4f', benchmark_test)
mod <- neuralnet(f, data = dat, hidden = 10, act.fct = "tanh", stepmax = 1e+07)
################################
#  Evaluate Results
################################
# predict the values using training and test set
Y_fit_train <- compute(mod, Xtrain)$net.result
Y_fit_test <- compute(mod, Xtest)$net.result
# MSE in scaled space
mse_train <- sqrt(mean((Y_fit_train - Ytrain)^2))
mse_test <- sqrt(mean((Y_fit_test - Ytest)^2))
# MSE of just choosing the mean (benchmark to beat)
benchmark_train <- sqrt(mean((Ytrain - mean(Ytrain))^2))
benchmark_test <- sqrt(mean((Ytest - mean(Ytest))^2))
sprintf("Training RMSE: %.4f", mse_train)
sprintf('... Training Benchmark: %.4f', benchmark_train)
sprintf("Testing RMSE: %.4f", mse_test)
sprintf('... Testing Benchmark: %.4f', benchmark_test)
mod <- neuralnet(f, data = dat, hidden = 3, act.fct = "tanh", stepmax = 1e+07)
################################
#  Evaluate Results
################################
# predict the values using training and test set
Y_fit_train <- compute(mod, Xtrain)$net.result
Y_fit_test <- compute(mod, Xtest)$net.result
# MSE in scaled space
mse_train <- sqrt(mean((Y_fit_train - Ytrain)^2))
mse_test <- sqrt(mean((Y_fit_test - Ytest)^2))
# MSE of just choosing the mean (benchmark to beat)
benchmark_train <- sqrt(mean((Ytrain - mean(Ytrain))^2))
benchmark_test <- sqrt(mean((Ytest - mean(Ytest))^2))
sprintf("Training RMSE: %.4f", mse_train)
sprintf('... Training Benchmark: %.4f', benchmark_train)
sprintf("Testing RMSE: %.4f", mse_test)
sprintf('... Testing Benchmark: %.4f', benchmark_test)
mod <- neuralnet(f, data = dat, hidden = 5, act.fct = "tanh", stepmax = 1e+07)
################################
#  Evaluate Results
################################
# predict the values using training and test set
Y_fit_train <- compute(mod, Xtrain)$net.result
Y_fit_test <- compute(mod, Xtest)$net.result
# MSE in scaled space
mse_train <- sqrt(mean((Y_fit_train - Ytrain)^2))
mse_test <- sqrt(mean((Y_fit_test - Ytest)^2))
# MSE of just choosing the mean (benchmark to beat)
benchmark_train <- sqrt(mean((Ytrain - mean(Ytrain))^2))
benchmark_test <- sqrt(mean((Ytest - mean(Ytest))^2))
sprintf("Training RMSE: %.4f", mse_train)
sprintf('... Training Benchmark: %.4f', benchmark_train)
sprintf("Testing RMSE: %.4f", mse_test)
sprintf('... Testing Benchmark: %.4f', benchmark_test)
